{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/noong99/stats507-coursework/tree/main/Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Datasets: finance-financialmodelingprep-stock-news-sentiments-rss-feed  \n",
    "https://huggingface.co/datasets/NickyNicky/finance-financialmodelingprep-stock-news-sentiments-rss-feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import  numpy as np\n",
    "# from pytorch_pretrained_bert import BertTokenizr\n",
    "# from bertModel import BertClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/news_data_sampled.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Data Preparation with LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train, test and validation.  \n",
    "Use the train data to train the model, the validation data to check the performance of the model, and the test data to check how the model performs on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Validation size: 800\n",
      "Train size: 800\n"
     ]
    }
   ],
   "source": [
    "# Set Title_Text as texts, sentiment as labels\n",
    "texts = df['Title_Text'].values\n",
    "labels = df['sentiment'].values\n",
    "scores = df['sentimentScore'].values\n",
    "\n",
    "# Split the data into train, validation, test set\n",
    "# Set train:valid:test = 6:2:2 and apply stratify\n",
    "xtrain, xtemp, ytrain, ytemp, scores_train, scores_temp= train_test_split(texts, labels, scores, test_size = 0.4, random_state = 129, stratify = labels)\n",
    "xtest, xvalid, ytest, yvalid, scores_valid, scores_test= train_test_split(xtemp, ytemp, scores_temp, test_size=0.5, random_state = 129, stratify = ytemp)\n",
    "\n",
    "# Check how many data in one each dataset\n",
    "print(f\"Train size: {len(xtrain)}\")\n",
    "print(f\"Validation size: {len(xvalid)}\")\n",
    "print(f\"Train size: {len(xtest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. PyTorch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, scores, tokenizer, max_len=128):\n",
    "        self.x = texts # Texts\n",
    "        self.y = labels # Sentiment\n",
    "        self.scores = scores # SentimentScore\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x) # length of Texts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        score = self.scores[index]\n",
    "        encoding = self.tokenizer(\n",
    "            x,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(y, dtype=torch.long),\n",
    "            \"score\": torch.tensor(score, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_dataset = SentimentDataset(xtrain, ytrain, scores_train, tokenizer)\n",
    "valid_dataset = SentimentDataset(xvalid, yvalid, scores_valid, tokenizer)\n",
    "test_dataset = SentimentDataset(xtest, ytest, scores_test, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim + 1, output_dim)  # +1 for sentimentScore\n",
    "\n",
    "    def forward(self, input_ids, scores):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        hidden_with_score = torch.cat((hidden.squeeze(0), scores.unsqueeze(1)), dim=1)\n",
    "        logits = self.fc(hidden_with_score)\n",
    "        return logits\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dim = len(set(labels))\n",
    "\n",
    "model = LSTMModel(embedding_dim, hidden_dim, output_dim, vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sentimentScore` in loss function(same method used in FinBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a weighted loss function\n",
    "def weighted_loss(outputs, labels, scores):\n",
    "    weights = 1 + scores\n",
    "    loss = nn.CrossEntropyLoss(reduction='none')(outputs, labels)\n",
    "    weighted_loss = (loss * weights).mean()  # Apply weights\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model train and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3002, Val Loss: 0.8252, Val Acc: 0.8925\n",
      "Epoch 2, Train Loss: 0.1984, Val Loss: 0.8821, Val Acc: 0.8925\n",
      "Epoch 3, Train Loss: 0.1890, Val Loss: 0.8770, Val Acc: 0.8925\n",
      "Epoch 4, Train Loss: 0.1779, Val Loss: 0.9304, Val Acc: 0.8925\n",
      "Epoch 5, Train Loss: 0.1570, Val Loss: 0.8635, Val Acc: 0.8938\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Use Adam Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train function\n",
    "def train_epoch(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"label\"]\n",
    "        scores = batch[\"score\"]\n",
    "\n",
    "        outputs = model(input_ids, scores)\n",
    "        loss = weighted_loss(outputs, labels, scores)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return np.mean(losses)\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            labels = batch[\"label\"]\n",
    "            scores = batch[\"score\"]\n",
    "\n",
    "            outputs = model(input_ids, scores)\n",
    "            loss = weighted_loss(outputs, labels, scores)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predictions.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    return np.mean(losses), accuracy_score(true_labels, predictions)\n",
    "\n",
    "# Training and evaluation\n",
    "for epoch in range(5):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer)\n",
    "    val_loss, val_acc = evaluate_model(model, valid_loader)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test Loss: 0.8204, Test Accuracy: 0.8925\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "test_loss, test_acc = evaluate_model(model, test_loader)\n",
    "print(f\"LSTM Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
