{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/noong99/stats507-coursework/tree/main/Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Datasets: finance-financialmodelingprep-stock-news-sentiments-rss-feed  \n",
    "https://huggingface.co/datasets/NickyNicky/finance-financialmodelingprep-stock-news-sentiments-rss-feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import  numpy as np\n",
    "# from pytorch_pretrained_bert import BertTokenizr\n",
    "# from bertModel import BertClassification\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/news_data_sampled.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FinBERT Embedding LSTM Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train, test and validation.  \n",
    "Use the train data to train the model, the validation data to check the performance of the model, and the test data to check how the model performs on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Validation size: 800\n",
      "Train size: 800\n"
     ]
    }
   ],
   "source": [
    "# Set Title_Text as texts, sentiment as labels\n",
    "texts = df['Title_Text'].values\n",
    "labels = df['sentiment'].values\n",
    "scores = df['sentimentScore'].values\n",
    "\n",
    "# Split the data into train, validation, test set\n",
    "# Set train:valid:test = 6:2:2 and apply stratify\n",
    "xtrain, xtemp, ytrain, ytemp, scores_train, scores_temp= train_test_split(texts, labels, scores, test_size = 0.4, random_state = 129, stratify = labels)\n",
    "xtest, xvalid, ytest, yvalid, scores_valid, scores_test= train_test_split(xtemp, ytemp, scores_temp, test_size=0.5, random_state = 129, stratify = ytemp)\n",
    "\n",
    "# Check how many data in one each dataset\n",
    "print(f\"Train size: {len(xtrain)}\")\n",
    "print(f\"Validation size: {len(xvalid)}\")\n",
    "print(f\"Train size: {len(xtest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Define PyTorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding with FinBERT and using `sentimentScore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinDataset(Dataset):\n",
    "    def __init__(self, texts, scores, labels):\n",
    "        self.x = pd.Series(texts) # Texts\n",
    "        self.scores = pd.Series(scores) # SentimentScore\n",
    "        self.y = pd.Series(labels) # Sentiment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoded = tokenizer(self.x.iloc[idx], padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
    "            'score': torch.tensor(self.scores.iloc[idx], dtype=torch.float32),\n",
    "            'label': torch.tensor(self.y.iloc[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = FinDataset(xtrain, scores_train, ytrain)\n",
    "test_dataset = FinDataset(xtest, scores_test, ytest)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step combines the sequential features learned by the LSTM with the standalone `sentimentScore` in the final decision-making step.   \n",
    " By doing so, the model can leverage both the contextual information from the sequence and the raw sentiment data to improve classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinBERTWithLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinBERTWithLSTM, self).__init__()\n",
    "        self.finbert = AutoModel.from_pretrained(\"ProsusAI/finbert\", num_labels = 3)\n",
    "        self.lstm = nn.LSTM(input_size=768, hidden_size = 128, batch_first=True)\n",
    "        self.fc = nn.Linear(128 + 1, 3)  # LSTM + SentimentScore\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, scores):\n",
    "        outputs = self.finbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        lstm_output, _ = self.lstm(outputs.last_hidden_state)\n",
    "        combined = torch.cat((lstm_output[:, -1, :], scores.unsqueeze(1)), dim=1)\n",
    "        logits = self.fc(combined)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        scores = batch['score']\n",
    "        labels = batch['label']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, scores)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define evaluation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            scores = batch['score']\n",
    "            labels = batch['label']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, scores)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(test_loader), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. Model train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.4250, Test Loss: 0.3128, Accuracy: 0.8912\n",
      "Epoch 2/5, Train Loss: 0.2986, Test Loss: 0.3096, Accuracy: 0.8825\n",
      "Epoch 3/5, Train Loss: 0.2317, Test Loss: 0.4160, Accuracy: 0.8013\n",
      "Epoch 4/5, Train Loss: 0.1731, Test Loss: 0.3286, Accuracy: 0.8875\n",
      "Epoch 5/5, Train Loss: 0.1223, Test Loss: 0.3672, Accuracy: 0.8812\n"
     ]
    }
   ],
   "source": [
    "model = FinBERTWithLSTM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5) # commonly used learning rate in BERT\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5 # commonly used learning rate\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion)\n",
    "    test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
